{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is first sentence.\n",
      "This is second sentence.\n",
      "This is third sentence\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp= spacy.load('en_core_web_sm')\n",
    "doc= nlp(u'This is first sentence. This is second sentence. This is third sentence')\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is first sentence."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doc[1] will give the token at that place but doc.sents[0] won't give the sentence at that index.\n",
    "#if you really need to grab a sentence at a specific index\n",
    "list(doc.sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m doc\n\u001b[0;32m     14\u001b[0m \u001b[39m# nlp.add_pipe(\"set_custom_segmentation\",before='parser')\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m doc\u001b[39m=\u001b[39m nlp(\u001b[39mu\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mManagement is doing the right thing ; Leadership is also doing the right thing\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m st \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39msents:\n\u001b[0;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(st\u001b[39m.\u001b[39mtext)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\spacy\\language.py:1031\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1031\u001b[0m     error_handler(name, proc, [doc], e)\n\u001b[0;32m   1032\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(doc, Doc):\n\u001b[0;32m   1033\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE005\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, returned_type\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(doc)))\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\spacy\\util.py:1670\u001b[0m, in \u001b[0;36mraise_error\u001b[1;34m(proc_name, proc, docs, e)\u001b[0m\n\u001b[0;32m   1669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_error\u001b[39m(proc_name, proc, docs, e):\n\u001b[1;32m-> 1670\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\spacy\\language.py:1026\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1024\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[0;32m   1025\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1026\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg\u001b[39m.\u001b[39mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1028\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m, in \u001b[0;36mset_custom_segmentation\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m@Language\u001b[39m\u001b[39m.\u001b[39mcomponent(\u001b[39m'\u001b[39m\u001b[39mset_custom_segmentation\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_custom_segmentation\u001b[39m(doc):\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc[:,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]:\n\u001b[0;32m      7\u001b[0m         \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mtext\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      8\u001b[0m             doc[token\u001b[39m.\u001b[39mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mis_sent_start\u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\spacy\\tokens\\doc.pyx:480\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.__getitem__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "#if you want the sentences to be separated by something else than '.' you've 2 options: either add a segmentation rule or change the segmentation rules\n",
    "#to add a segmentation rule: we define a function for this:\n",
    "from spacy.language import Language\n",
    "@Language.component('set_custom_segmentation')\n",
    "def set_custom_segmentation(doc):\n",
    "    for i,token in enumerate(doc[:,-1]):\n",
    "        if token.text==';':\n",
    "            doc[i+1].is_sent_start= True\n",
    "        else:\n",
    "            doc[i+1].is_sent_start= False\n",
    "    return doc\n",
    "\n",
    "\n",
    "# nlp.add_pipe(\"set_custom_segmentation\",before='parser')\n",
    "doc= nlp(u'Management is doing the right thing ; Leadership is also doing the right thing')\n",
    "for st in doc.sents:\n",
    "    print(st.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is. A sentence. ;\n",
      "This is. Another sentence.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"custom_sentencizer\")\n",
    "def custom_sentencizer(doc):\n",
    "    for i, token in enumerate(doc[:-2]):\n",
    "        # Define sentence start if pipe + titlecase token\n",
    "        if token.text == \";\" and doc[i + 1].is_title:\n",
    "            doc[i + 1].is_sent_start = True\n",
    "        else:\n",
    "            # Explicitly set sentence start to False otherwise, to tell\n",
    "            # the parser to leave those tokens alone\n",
    "            doc[i + 1].is_sent_start = False\n",
    "    return doc\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"custom_sentencizer\", before=\"parser\")  # Insert before the parser\n",
    "doc = nlp(\"This is. A sentence. ; This is. Another sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
